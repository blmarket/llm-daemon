[package]
name = "llm-daemon"
version.workspace = true
authors.workspace = true
edition = "2021"
license = "GPL-3.0-only"
keywords = ["llm"]
description = "LLM as a daemon"
readme = "README.md"
repository = "https://github.com/blmarket/llm-daemon"

[dependencies]
llama_cpp_low = { version = "0.3.5", path = "../llama-cpp-low" }
tracing = { workspace = true }
anyhow = { workspace = true }
tokio = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
axum = "0.7"
daemonize = "0.5"
futures = "0.3"
hyper = { version = "1", features = ["full"] }
hyper-util = { version = "0.1", features = ["full"] }
reqwest = { version = "0.12", default-features = false, features = ["json", "rustls-tls"] }
tempfile = "3"
url = "2"
tracing-subscriber = "0.3"

[dev-dependencies]
tracing-test = "0.2"
criterion = "0.5"
langchain-rust = "4"
async-trait = "0.1"

[features]
default = ["llama-daemon", "mlc-daemon"]
llama-daemon = []
mlc-daemon = []

[[bench]]
name = "port_open"
harness = false    
