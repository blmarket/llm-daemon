[package]
name = "llama_cpp_low"
version = "0.3.1-alpha.0"
edition = "2021"
license = "MIT"
keywords = ["llm"]
description = "small server binary compile build from llama.cpp"
homepage = "https://github.com/blmarket/llm-daemon"
repository = "https://github.com/blmarket/llm-daemon"
readme = "README.md"
exclude = ["llama.cpp/models/**", "llama.cpp/kompute/**"]

[dependencies]

[build-dependencies]
cmake = "0.1.50"

[features]
default = ["cuda"]
cuda = []
